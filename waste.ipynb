{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff12209-2555-400d-a833-0248162f4137",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model Training\n",
    "\n",
    "pip install tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "w = tf.constant(2.0)\n",
    "b = tf.constant(3.0)\n",
    "x = tf.constant(4.0)\n",
    "\n",
    "#y = tf.multiply(w,x)\n",
    "#y = tf.add(y,b)\n",
    "\n",
    "print(\"Output:\",w)\n",
    "print(\"Output:\",b)\n",
    "print(\"Output:\",x)\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Root directory\n",
    "dataset_dir = \"dataset\"\n",
    "\n",
    "base_dir = \"dataset\"\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "\n",
    "# Check subfolders\n",
    "print(\"Train subfolders:\", os.listdir(train_dir))\n",
    "print(\"Test subfolders:\", os.listdir(test_dir))\n",
    "# Collect all image paths from train and test\n",
    "image_paths = glob(os.path.join(dataset_dir, \"*/*/*.jpg\"))  # Change *.jpg if needed\n",
    "    \n",
    "# Print the total number of images\n",
    "print(f\"Total images in dataset: {len(image_paths)}\")\n",
    "\n",
    "# Resize image to a specific size\n",
    "def resize_image(image, size=(224, 224)):\n",
    "    return cv2.resize(image, size)\n",
    "\n",
    "# Normalize pixel values to range [0, 1]\n",
    "def normalize_image(image):\n",
    "    return image / 255.0\n",
    "\n",
    "# Display an image (for verification)\n",
    "def show_image(image, title=\"Image\"):\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def preprocess_and_save_all_images(image_paths, output_base_dir):\n",
    "    for path in image_paths:\n",
    "        # Read the image\n",
    "        image = cv2.imread(path)\n",
    "        if image is None:  # Handle unreadable images\n",
    "            print(f\"Warning: Unable to read image {path}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Resize and normalize the image\n",
    "        resized_image = resize_image(image)\n",
    "        normalized_image = normalize_image(resized_image)\n",
    "\n",
    "        # Reconstruct the new save path\n",
    "        relative_path = os.path.relpath(path, dataset_dir)  # Get relative path\n",
    "        save_path = os.path.join(output_base_dir, relative_path)  # Add base output directory\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)  # Create class-specific folder\n",
    "\n",
    "        # Save the processed image\n",
    "        cv2.imwrite(save_path, (normalized_image * 255).astype(np.uint8))\n",
    "\n",
    "# Display a sample preprocessed image\n",
    "sample_image_path = glob(os.path.join(output_dir, \"**\", \"*.jpg\"), recursive=True)  # Get preprocessed images\n",
    "if sample_image_path:\n",
    "    sample_image = cv2.imread(sample_image_path[0])  # Read the first preprocessed image\n",
    "    show_image(sample_image, title=\"Sample Preprocessed Image\")\n",
    "else:\n",
    "    print(\"No preprocessed images found.\")\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "train_path = \"./preprocessed/train\"  # Update with the dataset's train folder path\n",
    "test_path = \"./preprocessed/test\"   # Update with the dataset's test folder path\n",
    "\n",
    "batch_size = 32  # Adjust based on your system's GPU memory\n",
    "\n",
    "# Augment and normalize training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Normalize test data\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # For multi-class classification\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Model Architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layers with Batch Normalization\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
    "model.add(BatchNormalization())  # Normalizing layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Fully Connected Layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.6))  # Dropout to prevent overfitting\n",
    "model.add(Dense(2, activation='softmax'))  # Output layer with two classes (Organic and Recyclable)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),  # Learning rate\n",
    "    loss='categorical_crossentropy',  # Cross-entropy loss for classification\n",
    "    metrics=['accuracy']  # Accuracy as evaluation metric\n",
    ")\n",
    "train_path = './preprocessed/train'  # Directory for training data\n",
    "test_path = './preprocessed/test'    # Directory for test data\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "# Augment and normalize training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,  # Normalize images\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Normalize test data\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Create the training and testing data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'  # For multi-class classification\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "batch_size = 32  # Adjust based on your system's GPU memory\n",
    "\n",
    "# Augment and normalize training data\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Normalize test data\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # For multi-class classification\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint('best_waste_segregation_model.h5', save_best_only=True, monitor='val_loss', mode='min'),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)  # Reduce learning rate when loss plateaus\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=10,  # Adjust as per your needs\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=len(test_generator),\n",
    "    callbacks=callbacks  # Adding callbacks for early stopping and checkpointing\n",
    ")\n",
    "\n",
    "# Evaluate model on test data\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Plot Accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.show()\n",
    "\n",
    "# Plot Loss\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.show()\n",
    "\n",
    "model.save('waste_segregation_model.h5')  # Save the model\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"Preprocess a single image for prediction.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224, 224)) / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n",
    "\n",
    "def predict_image(image_path, model, class_names):\n",
    "    img = preprocess_image(image_path)\n",
    "    prediction = model.predict(img)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    print(f\"The image is classified as: {class_names[predicted_class]} \"\n",
    "          f\"(Confidence: {np.max(prediction)*100:.2f}%)\")\n",
    "\n",
    "# Class names from the train generator\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# Test predictions with sample images\n",
    "predict_image('./preprocessed/test/O/O_12573.jpg', model, class_names)\n",
    "predict_image('./preprocessed/test/R/R_10753.jpg', model, class_names)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "model.add(Dropout(0.5))  # Already present, try increasing to 0.6\n",
    "\n",
    "def predict_image(image_path, model, class_names):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224, 224)) / 255.0  # Normalize\n",
    "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
    "\n",
    "    prediction = model.predict(img)\n",
    "    predicted_index = np.argmax(prediction)  # Get predicted class index\n",
    "\n",
    "    # Ensure index matches class names correctly\n",
    "    predicted_label = class_names[predicted_index]\n",
    "\n",
    "    print(f\"The image is classified as: {predicted_label} (Confidence: {np.max(prediction)*100:.2f}%)\")\n",
    "\n",
    "print(train_generator.class_indices)\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load and recompile the model\n",
    "model = load_model('best_waste_segregation_model.h5')\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "class_names = list(train_generator.class_indices.keys())  # Ensure correct order\n",
    "\n",
    "test_images = ['./preprocessed/test/O/O_12573.jpg', './preprocessed/test/R/R_10753.jpg']\n",
    "\n",
    "for img_path in test_images:\n",
    "    predict_image(img_path, model, class_names)\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Function to display an image\n",
    "def show_image(image_path, title):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct colors\n",
    "    plt.imshow(img)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Paths for test dataset\n",
    "test_organic_path = \"./preprocessed/test/O\"\n",
    "test_recyclable_path = \"./preprocessed/test/R\"\n",
    "\n",
    "# Get image filenames from the directories\n",
    "test_organic_images = os.listdir(test_organic_path) if os.path.exists(test_organic_path) else []\n",
    "test_recyclable_images = os.listdir(test_recyclable_path) if os.path.exists(test_recyclable_path) else []\n",
    "\n",
    "# Display first 10 images from each category (if available)\n",
    "def show_multiple_images(images, title):\n",
    "    for i, image_name in enumerate(images[:20]):  # Display first 10 images\n",
    "        image_path = os.path.join(test_organic_path if title == \"Organic Waste\" else test_recyclable_path, image_name)\n",
    "        show_image(image_path, f\"{title} - Image {i + 1}\")\n",
    "\n",
    "if test_organic_images:\n",
    "    show_multiple_images(test_organic_images, \"Organic Waste\")\n",
    "else:\n",
    "    print(\"No Organic images found in the test set!\")\n",
    "\n",
    "if test_recyclable_images:\n",
    "    show_multiple_images(test_recyclable_images, \"Recyclable Waste\")\n",
    "else:\n",
    "    print(\"No Recyclable images found in the test set!\")\n",
    "\n",
    "\n",
    "APP.PY\n",
    "import streamlit as st\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from PIL import Image\n",
    "import base64\n",
    "\n",
    "# Function to Set Background Image\n",
    "def set_bg(image_path):\n",
    "    with open(image_path, \"rb\") as img_file:\n",
    "        encoded_string = base64.b64encode(img_file.read()).decode()\n",
    "    st.markdown(\n",
    "        f\"\"\"\n",
    "        <style>\n",
    "        .stApp {{\n",
    "            background-image: url(\"data:image/png;base64,{encoded_string}\");\n",
    "            background-size: cover;\n",
    "            background-position: center;\n",
    "            background-attachment: fixed;\n",
    "        }}\n",
    "        </style>\n",
    "        \"\"\",\n",
    "        unsafe_allow_html=True\n",
    "    )\n",
    "\n",
    "# Load Background Image\n",
    "set_bg(\"iws.png\")  # Ensure \"iws.png\" is in the same folder\n",
    "\n",
    "# Define Model Architecture\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(128, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Conv2D(256, (3, 3), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        Flatten(),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.6),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load Model\n",
    "model = create_model()\n",
    "model.load_weights('best_waste_segregation_model.h5')\n",
    "\n",
    "# Custom CSS for Styling\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    <style>\n",
    "    /* File Uploader Styling */\n",
    "    .file-uploader {\n",
    "        border: 2px dashed #ffffff;\n",
    "        padding: 20px;\n",
    "        text-align: center;\n",
    "        font-size: 18px;\n",
    "        font-family: 'Times New Roman', serif;\n",
    "        background: rgba(255, 255, 255, 0.2);\n",
    "        border-radius: 10px;\n",
    "        color: white;\n",
    "        margin-bottom: 20px;\n",
    "        \n",
    "    }\n",
    "\n",
    "    /* Centering Text */\n",
    "    .center-text {\n",
    "        text-align: center;\n",
    "        font-family: 'Times New Roman', serif;\n",
    "        color: white;\n",
    "    }\n",
    "\n",
    "    /* Prediction Box */\n",
    "    .prediction-box {\n",
    "        text-align: center;\n",
    "        font-size: 22px;\n",
    "        font-weight: bold;\n",
    "        color: white;\n",
    "        background: linear-gradient(to right, #00ff00, #00aaff);\n",
    "        padding: 10px;\n",
    "        border-radius: 10px;\n",
    "        display: inline-block;\n",
    "        margin-top: 20px;\n",
    "    }\n",
    "    </style>\n",
    "    \"\"\",\n",
    "    unsafe_allow_html=True\n",
    ")\n",
    "\n",
    "# Title\n",
    "st.markdown(\"<h1 class='center-text'>Waste Segregation Model</h1>\", unsafe_allow_html=True)\n",
    "\n",
    "# Styled File Uploader Box\n",
    "st.markdown(\"<div class='file-uploader'>Drag and drop an image here or click to upload</div>\", unsafe_allow_html=True)\n",
    "uploaded_file = st.file_uploader(\"\", type=[\"jpg\", \"png\", \"jpeg\"])\n",
    "\n",
    "# Process Image if Uploaded\n",
    "if uploaded_file is not None:\n",
    "    image = Image.open(uploaded_file)\n",
    "    \n",
    "    # Display Uploaded Image with Styling\n",
    "    st.markdown(\"<h3 class='center-text'>Uploaded Image:</h3>\", unsafe_allow_html=True)\n",
    "    st.image(image, caption=\"\", use_container_width=True)\n",
    "\n",
    "    # Preprocess Image\n",
    "    image = image.resize((224, 224))\n",
    "    image = np.array(image) / 255.0\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    # Make Prediction\n",
    "    prediction = model.predict(image)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    # Class labels\n",
    "    class_labels = [\"Organic\", \"Recyclable\"]\n",
    "\n",
    "    # Display Prediction\n",
    "    st.markdown(f\"<div class='prediction-box'>Predicted Class: {class_labels[predicted_class]}</div>\", unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "Frontend.py\n",
    "pip install streamlit h5py pandas\n",
    "\n",
    "import streamlit as st\n",
    "import h5py\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the model once when the app starts (outside the image upload process)\n",
    "@st.cache_resource\n",
    "def load_model():\n",
    "    model_path = 'best_waste_segregation_model.h5'\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    return model\n",
    "\n",
    "# Function to display the uploaded image\n",
    "def display_image(uploaded_file):\n",
    "    # Open the uploaded image file\n",
    "    image = Image.open(uploaded_file)\n",
    "    st.image(image, caption=\"Uploaded Image\", use_container_width=True)\n",
    "    return image\n",
    "\n",
    "# Load the model once\n",
    "model = load_model()\n",
    "\n",
    "# Step 1: Upload an image file\n",
    "uploaded_image = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_image is not None:\n",
    "    # Step 2: Display the uploaded image\n",
    "    image = display_image(uploaded_image)\n",
    "\n",
    "    # Step 3: Preprocess the uploaded image for the model (assuming the model requires resizing)\n",
    "    image = image.resize((224, 224))  # Resize to match model input size (if required by your model)\n",
    "    image = np.array(image)  # Convert image to numpy array\n",
    "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "    image = image / 255.0  # Normalize the image if required (depends on model)\n",
    "\n",
    "    # Show a progress bar to inform the user while prediction is happening\n",
    "    with st.spinner('Making prediction...'):\n",
    "        # Step 4: Make a prediction using the model\n",
    "        prediction = model.predict(image)\n",
    "\n",
    "    # Step 5: Display the prediction result (modify this based on your model's output)\n",
    "    st.write(\"Prediction Result:\")\n",
    "    st.write(prediction)  # Display the raw prediction, you can modify this depending on your model\n",
    "\n",
    "    # Optional: Show predicted class or result based on your model's output\n",
    "    predicted_class = np.argmax(prediction, axis=1)  # If it's a classification model\n",
    "    st.write(f\"Predicted Class: {predicted_class[0]}\")  # Show the predicted class\n",
    "\n",
    "!streamlit run app.py\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
